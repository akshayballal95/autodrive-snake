{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torchvision.transforms import transforms, Compose, ToTensor, Resize, Normalize, CenterCrop, Grayscale\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnakeDataSet(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, stack_size, transform = None):\n",
    "        self.stack_size = stack_size\n",
    "        self.key_frame = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.key_frame) - self.stack_size *3\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.to_list()\n",
    "        try:\n",
    "            img_names = [os.path.join(self.root_dir, self.key_frame.iloc[idx + i, 0]) for i in range(self.stack_size)]\n",
    "            images = [Image.open(img_name) for img_name in img_names]\n",
    "            label = torch.tensor(self.key_frame.iloc[idx + self.stack_size, 1])\n",
    "            if self.transform:\n",
    "                images = [self.transform(image) for image in images]\n",
    "        except:\n",
    "            img_names = [os.path.join(self.root_dir, self.key_frame.iloc[0 + i, 0]) for i in range(self.stack_size)]\n",
    "            images = [Image.open(img_name) for img_name in img_names]\n",
    "            label = torch.tensor(self.key_frame.iloc[0 + self.stack_size, 1])\n",
    "            if self.transform:\n",
    "                images = [self.transform(image) for image in images]\n",
    "        return torch.stack(images,dim = 1).squeeze(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Compose([\n",
    "    Grayscale(1),\n",
    "    Resize((84,84), antialias=True),\n",
    "    CenterCrop(84),\n",
    "    ToTensor(),\n",
    "    Normalize(mean =[0.6974], std =[0.6974] )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "STACK_SIZE = 4\n",
    "\n",
    "train, test = train_test_split(pd.read_csv(\"data/labels_snake.csv\")[:40000], test_size=0.2, shuffle=False)\n",
    "classes = [\"n\", \"left\", \"up\", \"right\", \"down\"]\n",
    "\n",
    "labels_unique, counts = np.unique(train[\"class\"], return_counts=True)\n",
    "class_weights = [sum(counts)/c for c in counts]\n",
    "example_weights = np.array([class_weights[l] for l in train['class']])\n",
    "example_weights = np.roll(example_weights, -STACK_SIZE)\n",
    "sampler = WeightedRandomSampler(example_weights, len(train))\n",
    "\n",
    "labels_unique, counts = np.unique(test[\"class\"], return_counts=True)\n",
    "class_weights = [sum(counts)/c for c in counts]\n",
    "test_example_weights = np.array([class_weights[l] for l in test['class']])\n",
    "test_example_weights = np.roll(test_example_weights, -STACK_SIZE)\n",
    "test_sampler = WeightedRandomSampler(test_example_weights, len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 32\n",
    "dataset = SnakeDataSet(root_dir=\"captures\", dataframe = train, stack_size=STACK_SIZE, transform=transformer)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=sampler, drop_last= True)\n",
    "test_dataset = SnakeDataSet(root_dir=\"captures\", dataframe = test, stack_size=STACK_SIZE,  transform=transformer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler = test_sampler, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(dataloader):\n",
    "    '''\n",
    "    We assume that the images of the dataloader have the same height and width\n",
    "    source: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/Basics/pytorch_std_mean.py\n",
    "    '''\n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_sqrd_sum, num_batches = 0, 0, 0\n",
    "\n",
    "    for batch_images, labels in tqdm(dataloader):  # (B,H,W,C)\n",
    "        batch_images = batch_images.permute(0,2,3,1)\n",
    "        channels_sum += torch.mean(batch_images, dim=[0, 1, 2])\n",
    "        channels_sqrd_sum += torch.mean(batch_images ** 2, dim=[0, 1, 2])\n",
    "        num_batches += 1\n",
    "\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_sqrd_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_mean_std(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 3, 2, 0, 2, 1, 0, 3, 1, 3, 2, 1, 2, 0, 0, 1, 2, 1, 0, 3, 2, 3, 1,\n",
      "        2, 0, 1, 3, 4, 3, 3, 2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, label = next(iter(dataloader))\n",
    "print(label)\n",
    "from matplotlib.pyplot import subplots\n",
    "fig,ax = subplots(1, STACK_SIZE, constrained_layout = True, figsize=(15,5))\n",
    "for i in range(STACK_SIZE):\n",
    "    ax[i].imshow(images[2][i,:,:],cmap=\"gray\");\n",
    "    ax[i].axis('off')\n",
    "fig.supylabel(classes[label[2].item()]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnakeModel(nn.Module):\n",
    "    def __init__(self, in_channels=4, out_channels=32, mlp_size=256, n_actions=5, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.mlp_size = mlp_size\n",
    "        self.n_classes = n_actions\n",
    "        self.convblock = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 4,2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier =nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=out_channels*9*9, out_features=mlp_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(in_features=mlp_size, out_features=n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.classifier(self.convblock(x).permute(0,2,3,1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SnakeModel                               [32, 5]                   --\n",
       "├─Sequential: 1-1                        [32, 32, 9, 9]            --\n",
       "│    └─Conv2d: 2-1                       [32, 16, 20, 20]          4,112\n",
       "│    └─ReLU: 2-2                         [32, 16, 20, 20]          --\n",
       "│    └─Conv2d: 2-3                       [32, 32, 9, 9]            8,224\n",
       "│    └─ReLU: 2-4                         [32, 32, 9, 9]            --\n",
       "├─Sequential: 1-2                        [32, 5]                   --\n",
       "│    └─Flatten: 2-5                      [32, 2592]                --\n",
       "│    └─Linear: 2-6                       [32, 256]                 663,808\n",
       "│    └─ReLU: 2-7                         [32, 256]                 --\n",
       "│    └─Dropout: 2-8                      [32, 256]                 --\n",
       "│    └─Linear: 2-9                       [32, 5]                   1,285\n",
       "==========================================================================================\n",
       "Total params: 677,429\n",
       "Trainable params: 677,429\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 95.23\n",
       "==========================================================================================\n",
       "Input size (MB): 3.61\n",
       "Forward/backward pass size (MB): 2.37\n",
       "Params size (MB): 2.71\n",
       "Estimated Total Size (MB): 8.69\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SnakeModel()\n",
    "summary(model, [BATCH_SIZE, 4, 84,84])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR\n",
    "num_epochs = 7\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 10e-5, weight_decay=0.1)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/7: 100%|██████████| 1000/1000 [07:17<00:00,  2.28it/s, Loss=0.0426, Accuracy=0.432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Val Loss: 0.0496, Val Accuracy: 0.3450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/7: 100%|██████████| 1000/1000 [06:51<00:00,  2.43it/s, Loss=0.0287, Accuracy=0.646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7, Val Loss: 0.0601, Val Accuracy: 0.3710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/7: 100%|██████████| 1000/1000 [06:34<00:00,  2.53it/s, Loss=0.0191, Accuracy=0.779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7, Val Loss: 0.0728, Val Accuracy: 0.3314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/7: 100%|██████████| 1000/1000 [06:27<00:00,  2.58it/s, Loss=0.0148, Accuracy=0.831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7, Val Loss: 0.0854, Val Accuracy: 0.3174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/7: 100%|██████████| 1000/1000 [06:35<00:00,  2.53it/s, Loss=0.0122, Accuracy=0.862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7, Val Loss: 0.0946, Val Accuracy: 0.3026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/7: 100%|██████████| 1000/1000 [07:11<00:00,  2.32it/s, Loss=0.0104, Accuracy=0.885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7, Val Loss: 0.1020, Val Accuracy: 0.2810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/7: 100%|██████████| 1000/1000 [07:51<00:00,  2.12it/s, Loss=0.0094, Accuracy=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7, Val Loss: 0.1100, Val Accuracy: 0.2891\n"
     ]
    }
   ],
   "source": [
    "steps = 0\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # tqdm bar for progress visualization\n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=True)\n",
    "    for inputs, labels in pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs.to(device))\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update statistics\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(torch.softmax(outputs,1), 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        # Update tqdm bar with current loss and accuracy\n",
    "        pbar.set_postfix({'Loss': total_loss / total_samples, 'Accuracy': correct_predictions / total_samples})\n",
    "        steps = steps + 1\n",
    "        # if steps>1000:\n",
    "        #     for param_group in optimizer.param_groups:\n",
    "        #         param_group['lr'] = 2e-5\n",
    "\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs.to(device))\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Update statistics\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(torch.softmax(outputs,1), 1)\n",
    "            val_correct_predictions += (predicted == labels).sum().item()\n",
    "            val_total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate and print epoch-level accuracy and loss for validation\n",
    "    epoch_loss = val_loss / val_total_samples\n",
    "    epoch_accuracy = val_correct_predictions / val_total_samples\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Val Loss: {epoch_loss:.4f}, Val Accuracy: {epoch_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autodrive-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
